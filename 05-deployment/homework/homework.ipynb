{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cd4ad49",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "* Install `uv`\n",
    "* What's the version of uv you installed?\n",
    "* Use `--version` to find out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef30fb73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uv 0.9.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "uv --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa9b1f0",
   "metadata": {},
   "source": [
    "## Initialize an empty uv project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f552d448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized project `\u001b[36mhomework\u001b[39m`\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "uv init"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff82ced4",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "* Use uv to install Scikit-Learn version 1.6.1 \n",
    "* What's the first hash for Scikit-Learn you get in the lock file?\n",
    "* Include the entire string starting with sha256:, don't include quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "941d88e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPython 3.12.1 interpreter at: \u001b[36m/home/codespace/.python/current/bin/python\u001b[39m\n",
      "Creating virtual environment at: \u001b[36m.venv\u001b[39m\n",
      "\u001b[2K\u001b[2mResolved \u001b[1m6 packages\u001b[0m \u001b[2min 464ms\u001b[0m\u001b[0m                                         \u001b[0m\n",
      "\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)                                                   \n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)--------------\u001b[0m\u001b[0m     0 B/12.54 MiB           \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)--------------\u001b[0m\u001b[0m 14.90 KiB/12.54 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)--------------\u001b[0m\u001b[0m 30.90 KiB/12.54 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)--------------\u001b[0m\u001b[0m 46.90 KiB/12.54 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)--------------\u001b[0m\u001b[0m 62.90 KiB/12.54 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)--------------\u001b[0m\u001b[0m 78.90 KiB/12.54 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)--------------\u001b[0m\u001b[0m 94.90 KiB/12.54 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)--------------\u001b[0m\u001b[0m 110.90 KiB/12.54 MiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)--------------\u001b[0m\u001b[0m 126.90 KiB/12.54 MiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)--------------\u001b[0m\u001b[0m 142.90 KiB/12.54 MiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)--------------\u001b[0m\u001b[0m 158.90 KiB/12.54 MiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)--------------\u001b[0m\u001b[0m 174.90 KiB/12.54 MiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)--------------\u001b[0m\u001b[0m 190.90 KiB/12.54 MiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)--------------\u001b[0m\u001b[0m 206.90 KiB/12.54 MiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)--------------\u001b[0m\u001b[0m 222.90 KiB/12.54 MiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)--------------\u001b[0m\u001b[0m 238.90 KiB/12.54 MiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)--------------\u001b[0m\u001b[0m 254.90 KiB/12.54 MiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)--------------\u001b[0m\u001b[0m 824.56 KiB/12.54 MiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)--------------\u001b[0m\u001b[0m 3.24 MiB/12.54 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)--------------\u001b[0m\u001b[0m 4.76 MiB/12.54 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)--------------\u001b[0m\u001b[0m 6.53 MiB/12.54 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)-\u001b[2m---------\u001b[0m\u001b[0m 8.53 MiB/12.54 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)-----\u001b[2m-----\u001b[0m\u001b[0m 10.35 MiB/12.54 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 366ms\u001b[0m\u001b[0m                                                  \u001b[1A\n",
      "\u001b[2K░░░░░░░░░░░░░░░░░░░░ [0/5] \u001b[2mInstalling wheels...                                 \u001b[0m\u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1mFailed to hardlink files; falling back to full copy. This may lead to degraded performance.\n",
      "         If the cache and target directories are on different filesystems, hardlinking may not be supported.\n",
      "         If this is intentional, set `export UV_LINK_MODE=copy` or use `--link-mode=copy` to suppress this warning.\u001b[0m\n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m5 packages\u001b[0m \u001b[2min 16.11s\u001b[0m\u001b[0m                              \u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjoblib\u001b[0m\u001b[2m==1.5.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==2.3.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mscikit-learn\u001b[0m\u001b[2m==1.6.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mscipy\u001b[0m\u001b[2m==1.16.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mthreadpoolctl\u001b[0m\u001b[2m==3.6.0\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "uv add \"scikit-learn==1.6.1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56005b5",
   "metadata": {},
   "source": [
    "The first hash for Scikit-Learn you get in uv.lock: `sha256:b4fc2525eca2c69a59260f583c56a7557c6ccdf8deafdba6e060f94c1c59738e`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28644996",
   "metadata": {},
   "source": [
    "\n",
    "## Models\n",
    "\n",
    "We have prepared a pipeline with a dictionary vectorizer and a model.\n",
    "\n",
    "It was trained (roughly) using this code:\n",
    "\n",
    "```\n",
    "categorical = ['lead_source']\n",
    "numeric = ['number_of_courses_viewed', 'annual_income']\n",
    "\n",
    "df[categorical] = df[categorical].fillna('NA')\n",
    "df[numeric] = df[numeric].fillna(0)\n",
    "\n",
    "train_dict = df[categorical + numeric].to_dict(orient='records')\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    DictVectorizer(),\n",
    "    LogisticRegression(solver='liblinear')\n",
    ")\n",
    "\n",
    "pipeline.fit(train_dict, y_train)\n",
    "```\n",
    "\n",
    "> **Note**: You don't need to train the model. This code is just for your reference.\n",
    "\n",
    "And then saved with Pickle. Download it [here](https://github.com/DataTalksClub/machine-learning-zoomcamp/tree/master/cohorts/2025/05-deployment/pipeline_v1.bin).\n",
    "\n",
    "With `wget`:\n",
    "\n",
    "```\n",
    "wget https://github.com/DataTalksClub/machine-learning-zoomcamp/raw/refs/heads/master/cohorts/2025/05-deployment/pipeline_v1.bin\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ddb7651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-10-27 17:27:18--  https://github.com/DataTalksClub/machine-learning-zoomcamp/raw/refs/heads/master/cohorts/2025/05-deployment/pipeline_v1.bin\n",
      "Resolving github.com (github.com)... 140.82.116.4\n",
      "Connecting to github.com (github.com)|140.82.116.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/DataTalksClub/machine-learning-zoomcamp/refs/heads/master/cohorts/2025/05-deployment/pipeline_v1.bin [following]\n",
      "--2025-10-27 17:27:19--  https://raw.githubusercontent.com/DataTalksClub/machine-learning-zoomcamp/refs/heads/master/cohorts/2025/05-deployment/pipeline_v1.bin\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1300 (1.3K) [application/octet-stream]\n",
      "Saving to: ‘pipeline_v1.bin’\n",
      "\n",
      "pipeline_v1.bin     100%[===================>]   1.27K  --.-KB/s    in 0s      \n",
      "\n",
      "2025-10-27 17:27:19 (81.8 MB/s) - ‘pipeline_v1.bin’ saved [1300/1300]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/DataTalksClub/machine-learning-zoomcamp/raw/refs/heads/master/cohorts/2025/05-deployment/pipeline_v1.bin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4673d1c1",
   "metadata": {},
   "source": [
    "\n",
    "## Question 3\n",
    "\n",
    "Let's use the model!\n",
    "\n",
    "* Write a script for loading the pipeline with pickle\n",
    "* Score this record:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"lead_source\": \"paid_ads\",\n",
    "    \"number_of_courses_viewed\": 2,\n",
    "    \"annual_income\": 79276.0\n",
    "}\n",
    "```\n",
    "\n",
    "What's the probability that this lead will convert? \n",
    "\n",
    "* 0.333\n",
    "* 0.533\n",
    "* 0.733\n",
    "* 0.933\n",
    "\n",
    "If you're getting errors when unpickling the files, check their checksum:\n",
    "\n",
    "```bash\n",
    "$ md5sum pipeline_v1.bin\n",
    "7d17d2e4dfbaf1e408e1a62e6e880d49 *pipeline_v1.bin\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abe38801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.46639273 0.53360727]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/base.py:440: InconsistentVersionWarning: Trying to unpickle estimator DictVectorizer from version 1.6.1 when using version 1.7.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/base.py:440: InconsistentVersionWarning: Trying to unpickle estimator LogisticRegression from version 1.6.1 when using version 1.7.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/base.py:440: InconsistentVersionWarning: Trying to unpickle estimator Pipeline from version 1.6.1 when using version 1.7.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open(\"pipeline_v1.bin\", \"rb\") as f_in:\n",
    "    pipeline = pickle.load(f_in)\n",
    "    \n",
    "    record= {\n",
    "        \"lead_source\": \"paid_ads\",\n",
    "        \"number_of_courses_viewed\": 2,\n",
    "        \"annual_income\": 79276.0\n",
    "    }\n",
    "    print(pipeline.predict_proba([record]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba0bd57",
   "metadata": {},
   "source": [
    "The probability that this lead will convert is `0.533`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3981fbf",
   "metadata": {},
   "source": [
    "\n",
    "## Question 4\n",
    "\n",
    "Now let's serve this model as a web service\n",
    "\n",
    "* Install FastAPI\n",
    "* Write FastAPI code for serving the model\n",
    "* Now score this client using `requests`:\n",
    "\n",
    "```python\n",
    "url = \"YOUR_URL\"\n",
    "client = {\n",
    "    \"lead_source\": \"organic_search\",\n",
    "    \"number_of_courses_viewed\": 4,\n",
    "    \"annual_income\": 80304.0\n",
    "}\n",
    "requests.post(url, json=client).json()\n",
    "```\n",
    "\n",
    "What's the probability that this client will get a subscription?\n",
    "\n",
    "* 0.334\n",
    "* 0.534\n",
    "* 0.734\n",
    "* 0.934"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14ed731",
   "metadata": {},
   "source": [
    "The probability that this client will get a subscription is `0.534`. I obtained this probability by running python test_convert.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e281ac8",
   "metadata": {},
   "source": [
    "## Docker\n",
    "\n",
    "Install [Docker](https://github.com/DataTalksClub/machine-learning-zoomcamp/blob/master/05-deployment/06-docker.md). \n",
    "We will use it for the next two questions.\n",
    "\n",
    "For these questions, we prepared a base image: `agrigorev/zoomcamp-model:2025`. \n",
    "You'll need to use it (see Question 5 for an example).\n",
    "\n",
    "This image is based on `3.13.5-slim-bookworm` and has\n",
    "a pipeline with logistic regression (a different one)\n",
    "as well a dictionary vectorizer inside. \n",
    "\n",
    "This is how the Dockerfile for this image looks like:\n",
    "\n",
    "```docker \n",
    "FROM python:3.13.5-slim-bookworm\n",
    "WORKDIR /code\n",
    "COPY pipeline_v2.bin .\n",
    "```\n",
    "\n",
    "We already built it and then pushed it to [`agrigorev/zoomcamp-model:2025`](https://hub.docker.com/r/agrigorev/zoomcamp-model).\n",
    "\n",
    "> **Note**: You don't need to build this docker image, it's just for your reference.\n",
    "\n",
    "\n",
    "## Question 5\n",
    "\n",
    "Download the base image `agrigorev/zoomcamp-model:2025`. You can easily make it by using [docker pull](https://docs.docker.com/engine/reference/commandline/pull/) command.\n",
    "\n",
    "So what's the size of this base image?\n",
    "\n",
    "* 45 MB\n",
    "* 121 MB\n",
    "* 245 MB\n",
    "* 330 MB\n",
    "\n",
    "You can get this information when running `docker images` - it'll be in the \"SIZE\" column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd70ca4",
   "metadata": {},
   "source": [
    "The size of this image is `121MB`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dadf29a",
   "metadata": {},
   "source": [
    "## Dockerfile\n",
    "\n",
    "Now create your own `Dockerfile` based on the image we prepared.\n",
    "\n",
    "It should start like that:\n",
    "\n",
    "```docker\n",
    "FROM agrigorev/zoomcamp-model:2025\n",
    "# add your stuff here\n",
    "```\n",
    "\n",
    "Now complete it:\n",
    "\n",
    "* Install all the dependencies from pyproject.toml\n",
    "* Copy your FastAPI script\n",
    "* Run it with uvicorn \n",
    "\n",
    "After that, you can build your docker image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1541afe4",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "\n",
    "Let's run your docker container!\n",
    "\n",
    "After running it, score this client once again:\n",
    "\n",
    "```python\n",
    "url = \"YOUR_URL\"\n",
    "client = {\n",
    "    \"lead_source\": \"organic_search\",\n",
    "    \"number_of_courses_viewed\": 4,\n",
    "    \"annual_income\": 80304.0\n",
    "}\n",
    "requests.post(url, json=client).json()\n",
    "```\n",
    "\n",
    "What's the probability that this lead will convert?\n",
    "\n",
    "* 0.39\n",
    "* 0.59\n",
    "* 0.79\n",
    "* 0.99"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515a7253",
   "metadata": {},
   "source": [
    "The probability that this lead will convert is 0.534. Hence, I choose the closest option, which is `0.59`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
